{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence with note: [' Compliant with diuretics but not following low sodium diet or fluid restriction']\n",
      "stigmatizing language: Compliant\n",
      "replace the stigmatizing word: \"Compliant\" with person-first language in the sentence: \" Compliant with diuretics but not following low sodium diet or fluid restriction\". Return the corrected sentence. Respond only with valid JSON. Do not write an introduction or a summary\n",
      "{\"person\": {\"condition\": \"chronic kidney disease\", \"medication\": \"diuretics\"}}\n",
      "{'condition': 'chronic kidney disease', 'medication': 'diuretics'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 50\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# print(entireFile)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m model \u001b[38;5;241m=\u001b[39m OllamaLLM(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3.2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43maskLlama\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreplace the stigmatizing word: \u001b[39;49m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstigmatizingWord\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;124;43m with person-first language in the sentence: \u001b[39;49m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msentenceWithNote\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;124;43m. Return the corrected sentence. Respond only with valid JSON. Do not write an introduction or a summary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentenceWithNote\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[30], line 19\u001b[0m, in \u001b[0;36maskLlama\u001b[0;34m(prompt, OGsentence)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(a\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mSequenceMatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOGsentence\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SequenceMatcher(\u001b[38;5;28;01mNone\u001b[39;00m, i, OGsentence)\u001b[38;5;241m.\u001b[39mratio() \u001b[38;5;241m>\u001b[39m highestStringSimilarity \u001b[38;5;129;01mand\u001b[39;00m SequenceMatcher(\u001b[38;5;28;01mNone\u001b[39;00m, i, OGsentence)\u001b[38;5;241m.\u001b[39mratio() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     21\u001b[0m         highestStringSimilarity \u001b[38;5;241m=\u001b[39m SequenceMatcher(\u001b[38;5;28;01mNone\u001b[39;00m, i, OGsentence)\u001b[38;5;241m.\u001b[39mratio()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/difflib.py:619\u001b[0m, in \u001b[0;36mSequenceMatcher.ratio\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mratio\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    598\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a measure of the sequences' similarity (float in [0,1]).\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03m    Where T is the total number of elements in both sequences, and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03m    1.0\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 619\u001b[0m     matches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(triple[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m triple \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_matching_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _calculate_ratio(matches, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/difflib.py:454\u001b[0m, in \u001b[0;36mSequenceMatcher.get_matching_blocks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m queue:\n\u001b[1;32m    453\u001b[0m     alo, ahi, blo, bhi \u001b[38;5;241m=\u001b[39m queue\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m--> 454\u001b[0m     i, j, k \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_longest_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43malo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mahi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbhi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# a[alo:i] vs b[blo:j] unknown\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;66;03m# a[i:i+k] same as b[j:j+k]\u001b[39;00m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;66;03m# a[i+k:ahi] vs b[j+k:bhi] unknown\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k:   \u001b[38;5;66;03m# if k is 0, there was no matching block\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/difflib.py:379\u001b[0m, in \u001b[0;36mSequenceMatcher.find_longest_match\u001b[0;34m(self, alo, ahi, blo, bhi)\u001b[0m\n\u001b[1;32m    377\u001b[0m j2lenget \u001b[38;5;241m=\u001b[39m j2len\u001b[38;5;241m.\u001b[39mget\n\u001b[1;32m    378\u001b[0m newj2len \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 379\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m b2j\u001b[38;5;241m.\u001b[39mget(\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, nothing):\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# a[i] matches b[j]\u001b[39;00m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m<\u001b[39m blo:\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from langchain_ollama import OllamaLLM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "stigmatizingLanguage = []\n",
    "\n",
    "def askLlama(prompt, OGsentence):\n",
    "    print(prompt)\n",
    "    result = model.invoke(input=prompt)\n",
    "    print(result)\n",
    "    a = ast.literal_eval(result)\n",
    "    highestStringSimilarity = 0\n",
    "    string = \"\"\n",
    "    for i in list(a.values()):\n",
    "        print(i)\n",
    "        print(SequenceMatcher(None, i, OGsentence).ratio())\n",
    "        if SequenceMatcher(None, i, OGsentence).ratio() > highestStringSimilarity and SequenceMatcher(None, i, OGsentence).ratio() < 1:\n",
    "            highestStringSimilarity = SequenceMatcher(None, i, OGsentence).ratio()\n",
    "            string = i\n",
    "    return string\n",
    "\n",
    "# Creates a 2D array with first element as the note number with the bad stuff and the second element as the identified word\n",
    "with open(\"listOfAllStigmatizingLanguage.txt\") as f:\n",
    "    for i in f.read().split(\"\\n\"):\n",
    "        stigmatizingLanguage.append([list(ast.literal_eval(i).keys())[0], list(ast.literal_eval(i).values())[0][0]])\n",
    "\n",
    "stigmatizingLanguageArray = np.array(stigmatizingLanguage, dtype=object)\n",
    "\n",
    "# shortens array to 5 elements\n",
    "stigmatizingLanguageArray = np.array(stigmatizingLanguageArray[0], dtype=object)\n",
    "\n",
    "stuffToCheck = []\n",
    "with open(f\"/Users/sagewong/Documents/allClinicalNotes/note{stigmatizingLanguageArray[0]}.txt\") as file:\n",
    "    entireFile = file.read()\n",
    "    fileListSentences = entireFile.replace(\"\\n\", \"\").split(\".\")\n",
    "    # list comprehension [sentence, keyvalue[1]] is the output, loops through every sentence in fileListSentences and returns output if keyValue[1] in sentence\n",
    "    matchingSentence = [sentence for sentence in fileListSentences if stigmatizingLanguageArray[1] in sentence]\n",
    "    stuffToCheck.append({\"sentence with note\": matchingSentence, \"stigmatizing language\": stigmatizingLanguageArray[1], \"file path\": f\"/Users/sagewong/Documents/allClinicalNotes/note{stigmatizingLanguageArray[0]}.txt\"})\n",
    "sentenceWithNote = stuffToCheck[0]['sentence with note']\n",
    "stigmatizingWord = stuffToCheck[0]['stigmatizing language']\n",
    "print(f\"sentence with note: {sentenceWithNote}\")\n",
    "print(f\"stigmatizing language: {stigmatizingWord}\")\n",
    "# print(entireFile)\n",
    "\n",
    "model = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "result = askLlama(f\"replace the stigmatizing word: \\\"{stigmatizingWord}\\\" with person-first language in the sentence: \\\"{sentenceWithNote[0]}\\\". Return the corrected sentence. Respond only with valid JSON. Do not write an introduction or a summary\", sentenceWithNote)\n",
    "print(f\"result: {result}\")\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
