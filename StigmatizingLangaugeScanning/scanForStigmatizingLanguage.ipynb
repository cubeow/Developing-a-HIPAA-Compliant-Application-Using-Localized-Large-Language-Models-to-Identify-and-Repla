{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of         Unnamed: 0                                               text  \\\n",
      "0                0   \\nName:  ___                     Unit No:   _...   \n",
      "1                1   \\nName:  ___                     Unit No:   _...   \n",
      "2                2   \\nName:  ___                     Unit No:   _...   \n",
      "3                3   \\nName:  ___                     Unit No:   _...   \n",
      "4                4   \\nName:  ___                    Unit No:   __...   \n",
      "...            ...                                                ...   \n",
      "331788      331788   \\nName:  ___                   Unit No:   ___...   \n",
      "331789      331789   \\nName:  ___                   Unit No:   ___...   \n",
      "331790      331790   \\nName:  ___                  Unit No:   ___\\...   \n",
      "331791      331791   \\nName:  ___                  Unit No:   ___\\...   \n",
      "331792      331792   \\nName:  ___                    Unit No:   __...   \n",
      "\n",
      "        stigmatizing_language  \n",
      "0                         NaN  \n",
      "1                         NaN  \n",
      "2                         NaN  \n",
      "3                         NaN  \n",
      "4                         NaN  \n",
      "...                       ...  \n",
      "331788                    NaN  \n",
      "331789                    NaN  \n",
      "331790                    NaN  \n",
      "331791                    NaN  \n",
      "331792                    NaN  \n",
      "\n",
      "[331793 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = \"/Users/sagewong/git/StigmatizingLanguageProject/SubtleStigmatizingLanguageScanning/mimic-iv-note-simplified.csv\"\n",
    "chunk_size = 1000\n",
    "chunks = []\n",
    "\n",
    "for chunk in pd.read_csv(file_path, chunksize = chunk_size):\n",
    "    chunks.append(chunk)\n",
    "\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "print(df.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/sagewong/Documents/allClinicalNotes/note\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 4\u001b[0m         \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loops through every row in the dataframe and then writes each row into a separate note{index}.txt file\n",
    "for i in range(0, df.shape[0]):\n",
    "    with open(f\"/Users/sagewong/Documents/allClinicalNotes/note{i}.txt\", \"w\") as file:\n",
    "        file.write(df['text'].iloc[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sickler']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m matches \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m clinicalRecord\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m listOfWords]\n\u001b[1;32m      9\u001b[0m fileListSentences \u001b[38;5;241m=\u001b[39m clinicalRecord\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m matchingSentence \u001b[38;5;241m=\u001b[39m [sentence \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m fileListSentences \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmatches\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01min\u001b[39;00m sentence]\n\u001b[1;32m     11\u001b[0m badDict[index] \u001b[38;5;241m=\u001b[39m matches\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m matches:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# with open(\"/Users/sagewong/git/StigmatizingLanguageProject/stigmatizingWords.txt\") as f:\n",
    "#     a = f.read()\n",
    "# listOfWords = a.split(\"\\n\")\n",
    "listOfWords = [\"sickler\"]\n",
    "print(listOfWords)\n",
    "badDict = {}\n",
    "for index, clinicalRecord in enumerate(list(df['text'])):\n",
    "    matches = [x for x in clinicalRecord.split() if x in listOfWords]\n",
    "    fileListSentences = clinicalRecord.replace(\"\\n\", \"\").split(\".\")\n",
    "    matchingSentence = [sentence for sentence in fileListSentences if matches[0] in sentence]\n",
    "    badDict[index] = matches\n",
    "    if matches:\n",
    "        print({index:matches, \"Sentence\":matchingSentence})\n",
    "print(badDict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
